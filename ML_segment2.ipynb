{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10194e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc88910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the connection to our Postgres db \n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'postgres' \n",
    "POSTGRES_PASSWORD = db_password\n",
    "POSTGRES_DBNAME = 'db_segment2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdebd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE THIS TO YOUR DATABASE NAME\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n",
    ".format(username=POSTGRES_USERNAME,\n",
    "password=POSTGRES_PASSWORD,\n",
    "ipaddress=POSTGRES_ADDRESS,\n",
    "port=POSTGRES_PORT,\n",
    "dbname=POSTGRES_DBNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45388c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection\n",
    "cnx = create_engine(postgres_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc44270b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the file\n",
    "merge = pd.read_sql_query('''SELECT * FROM merge;''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c19497",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>ell_num</th>\n",
       "      <th>sped_num</th>\n",
       "      <th>asian_num</th>\n",
       "      <th>black_num</th>\n",
       "      <th>hispanic_num</th>\n",
       "      <th>white_num</th>\n",
       "      <th>male_num</th>\n",
       "      <th>female_num</th>\n",
       "      <th>Total Cohort #</th>\n",
       "      <th>...</th>\n",
       "      <th># Male</th>\n",
       "      <th># Asian</th>\n",
       "      <th># Black</th>\n",
       "      <th># Hispanic</th>\n",
       "      <th># Multi-Racial</th>\n",
       "      <th># Native American</th>\n",
       "      <th># White</th>\n",
       "      <th># English Language Learners</th>\n",
       "      <th># Poverty</th>\n",
       "      <th>Economic Need Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>52.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>56</td>\n",
       "      <td>158</td>\n",
       "      <td>272</td>\n",
       "      <td>12</td>\n",
       "      <td>281.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>191.00</td>\n",
       "      <td>87.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>54.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>110</td>\n",
       "      <td>128</td>\n",
       "      <td>232</td>\n",
       "      <td>18</td>\n",
       "      <td>275.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>267</td>\n",
       "      <td>141</td>\n",
       "      <td>100</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>415.00</td>\n",
       "      <td>82.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>34</td>\n",
       "      <td>145</td>\n",
       "      <td>326</td>\n",
       "      <td>33</td>\n",
       "      <td>285.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>81</td>\n",
       "      <td>113</td>\n",
       "      <td>367</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>447.00</td>\n",
       "      <td>62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "      <td>96.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>176.00</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M515</td>\n",
       "      <td>462.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>501</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>314.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>318</td>\n",
       "      <td>58</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>392</td>\n",
       "      <td>431.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>32K549</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>310.00</td>\n",
       "      <td>92.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>32K552</td>\n",
       "      <td>69.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>187.15</td>\n",
       "      <td>91.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>32K554</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>373.00</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>32K556</td>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>266.95</td>\n",
       "      <td>92.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>32K564</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>219</td>\n",
       "      <td>4</td>\n",
       "      <td>158.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>226.00</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBN  ell_num  sped_num  asian_num  black_num  hispanic_num  white_num  \\\n",
       "0    01M292     52.0     124.0         56        158           272         12   \n",
       "1    01M448     54.0     111.0        110        128           232         18   \n",
       "2    01M450     27.0     146.0         34        145           326         33   \n",
       "3    01M458      4.0      19.0          3         59           136          8   \n",
       "4    01M515    462.0       4.0        501         24            24          2   \n",
       "..      ...      ...       ...        ...        ...           ...        ...   \n",
       "405  32K549     52.0      53.0          3         97           237          1   \n",
       "406  32K552     69.0      47.0          5        112           239          3   \n",
       "407  32K554     10.0      15.0          6         53           174          1   \n",
       "408  32K556     58.0      35.0          5         54           231          1   \n",
       "409  32K564     14.0      21.0          2        132           219          4   \n",
       "\n",
       "     male_num  female_num  Total Cohort #  ...  # Male  # Asian  # Black  \\\n",
       "0       281.0       234.0               5  ...     125       27       58   \n",
       "1       275.0       213.0              59  ...     267      141      100   \n",
       "2       285.0       261.0              76  ...     366       81      113   \n",
       "3        96.0       117.0              70  ...      86        1       70   \n",
       "4       314.0       237.0             234  ...     320      318       58   \n",
       "..        ...         ...             ...  ...     ...      ...      ...   \n",
       "405     167.0       180.0              57  ...     194        4       69   \n",
       "406     193.0       170.0              85  ...     112        2       35   \n",
       "407     120.0       117.0               5  ...     194       31       36   \n",
       "408     122.0       178.0              77  ...     155        2       48   \n",
       "409     158.0       199.0             173  ...     137        0       81   \n",
       "\n",
       "     # Hispanic  # Multi-Racial  # Native American  # White  \\\n",
       "0           127               0                  4        6   \n",
       "1           206               1                  2       15   \n",
       "2           367               6                  6      100   \n",
       "3           121               1                  1        9   \n",
       "4           165               0                  6       10   \n",
       "..          ...             ...                ...      ...   \n",
       "405         275               1                  2       11   \n",
       "406         154               0                  0        4   \n",
       "407         332               0                  0       35   \n",
       "408         222               0                  0        3   \n",
       "409         177               0                  0        5   \n",
       "\n",
       "    # English Language Learners # Poverty  Economic Need Index  \n",
       "0                            21    191.00                 87.8  \n",
       "1                            49    415.00                 82.9  \n",
       "2                             6    447.00                 62.9  \n",
       "3                            16    176.00                 85.0  \n",
       "4                           392    431.00                 95.0  \n",
       "..                          ...       ...                  ...  \n",
       "405                         118    310.00                 92.1  \n",
       "406                          51    187.15                 91.2  \n",
       "407                           7    373.00                 70.8  \n",
       "408                          75    266.95                 92.7  \n",
       "409                          19    226.00                 90.7  \n",
       "\n",
       "[410 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df = pd.DataFrame(merge)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54507522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBN                            410\n",
       "ell_num                        400\n",
       "sped_num                       398\n",
       "asian_num                      410\n",
       "black_num                      410\n",
       "hispanic_num                   410\n",
       "white_num                      410\n",
       "male_num                       404\n",
       "female_num                     409\n",
       "Total Cohort #                 410\n",
       "Total Grads #                  410\n",
       "Total Regents #                410\n",
       "Advanced Regents #             410\n",
       "Regents w/o Advanced #         410\n",
       "Local #                        410\n",
       "Still Enrolled #               410\n",
       "Dropped Out #                  410\n",
       "School Name                    410\n",
       "Year                           410\n",
       "Total Enrollment               410\n",
       "# Female                       410\n",
       "# Male                         410\n",
       "# Asian                        410\n",
       "# Black                        410\n",
       "# Hispanic                     410\n",
       "# Multi-Racial                 410\n",
       "# Native American              410\n",
       "# White                        410\n",
       "# English Language Learners    410\n",
       "# Poverty                      410\n",
       "Economic Need Index            410\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts the number of not empty values for each row\n",
    "merge_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf02185f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill null values with zero\n",
    "merge_df = merge_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7589f06a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBN                            410\n",
       "ell_num                        410\n",
       "sped_num                       410\n",
       "asian_num                      410\n",
       "black_num                      410\n",
       "hispanic_num                   410\n",
       "white_num                      410\n",
       "male_num                       410\n",
       "female_num                     410\n",
       "Total Cohort #                 410\n",
       "Total Grads #                  410\n",
       "Total Regents #                410\n",
       "Advanced Regents #             410\n",
       "Regents w/o Advanced #         410\n",
       "Local #                        410\n",
       "Still Enrolled #               410\n",
       "Dropped Out #                  410\n",
       "School Name                    410\n",
       "Year                           410\n",
       "Total Enrollment               410\n",
       "# Female                       410\n",
       "# Male                         410\n",
       "# Asian                        410\n",
       "# Black                        410\n",
       "# Hispanic                     410\n",
       "# Multi-Racial                 410\n",
       "# Native American              410\n",
       "# White                        410\n",
       "# English Language Learners    410\n",
       "# Poverty                      410\n",
       "Economic Need Index            410\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts the number of not empty values for each row\n",
    "merge_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b52654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ell_num</th>\n",
       "      <th>sped_num</th>\n",
       "      <th>asian_num</th>\n",
       "      <th>black_num</th>\n",
       "      <th>hispanic_num</th>\n",
       "      <th>white_num</th>\n",
       "      <th>male_num</th>\n",
       "      <th>female_num</th>\n",
       "      <th>Total Cohort #</th>\n",
       "      <th>Total Grads #</th>\n",
       "      <th>...</th>\n",
       "      <th># Male</th>\n",
       "      <th># Asian</th>\n",
       "      <th># Black</th>\n",
       "      <th># Hispanic</th>\n",
       "      <th># Multi-Racial</th>\n",
       "      <th># Native American</th>\n",
       "      <th># White</th>\n",
       "      <th># English Language Learners</th>\n",
       "      <th># Poverty</th>\n",
       "      <th>Economic Need Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.819512</td>\n",
       "      <td>74.997561</td>\n",
       "      <td>110.051220</td>\n",
       "      <td>210.080488</td>\n",
       "      <td>258.573171</td>\n",
       "      <td>102.375610</td>\n",
       "      <td>347.339024</td>\n",
       "      <td>347.207317</td>\n",
       "      <td>97.502439</td>\n",
       "      <td>70.463415</td>\n",
       "      <td>...</td>\n",
       "      <td>355.360976</td>\n",
       "      <td>125.875610</td>\n",
       "      <td>177.643902</td>\n",
       "      <td>275.914634</td>\n",
       "      <td>4.063415</td>\n",
       "      <td>6.802439</td>\n",
       "      <td>102.631707</td>\n",
       "      <td>83.951220</td>\n",
       "      <td>523.686707</td>\n",
       "      <td>77.078537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.477077</td>\n",
       "      <td>102.841928</td>\n",
       "      <td>312.717664</td>\n",
       "      <td>276.294828</td>\n",
       "      <td>356.055723</td>\n",
       "      <td>294.730311</td>\n",
       "      <td>493.595733</td>\n",
       "      <td>462.590868</td>\n",
       "      <td>144.222242</td>\n",
       "      <td>111.591575</td>\n",
       "      <td>...</td>\n",
       "      <td>417.913090</td>\n",
       "      <td>339.852782</td>\n",
       "      <td>178.264522</td>\n",
       "      <td>257.617379</td>\n",
       "      <td>12.390385</td>\n",
       "      <td>13.142160</td>\n",
       "      <td>273.181864</td>\n",
       "      <td>128.573583</td>\n",
       "      <td>540.472580</td>\n",
       "      <td>15.901799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>23.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>109.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>268.750000</td>\n",
       "      <td>70.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>365.500000</td>\n",
       "      <td>80.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>84.750000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>292.500000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>308.500000</td>\n",
       "      <td>321.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>338.500000</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>214.500000</td>\n",
       "      <td>331.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>84.750000</td>\n",
       "      <td>487.837500</td>\n",
       "      <td>88.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1095.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>3104.000000</td>\n",
       "      <td>1934.000000</td>\n",
       "      <td>2903.000000</td>\n",
       "      <td>3123.000000</td>\n",
       "      <td>3002.000000</td>\n",
       "      <td>2442.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3531.000000</td>\n",
       "      <td>3545.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1602.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3020.000000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ell_num    sped_num    asian_num    black_num  hispanic_num  \\\n",
       "count   410.000000  410.000000   410.000000   410.000000    410.000000   \n",
       "mean     73.819512   74.997561   110.051220   210.080488    258.573171   \n",
       "std     147.477077  102.841928   312.717664   276.294828    356.055723   \n",
       "min       0.000000    0.000000     0.000000     0.000000      7.000000   \n",
       "25%       6.000000   14.000000     4.000000    59.250000     56.500000   \n",
       "50%      20.000000   41.000000    11.000000   125.000000    159.000000   \n",
       "75%      61.000000   84.750000    55.500000   236.500000    292.500000   \n",
       "max    1095.000000  733.000000  3104.000000  1934.000000   2903.000000   \n",
       "\n",
       "         white_num     male_num   female_num  Total Cohort #  Total Grads #  \\\n",
       "count   410.000000   410.000000   410.000000      410.000000     410.000000   \n",
       "mean    102.375610   347.339024   347.207317       97.502439      70.463415   \n",
       "std     294.730311   493.595733   462.590868      144.222242     111.591575   \n",
       "min       0.000000     0.000000     0.000000        5.000000       1.000000   \n",
       "25%       3.000000    91.250000    98.500000       25.000000      12.000000   \n",
       "50%       8.500000   182.500000   203.000000       64.500000      42.000000   \n",
       "75%      41.500000   308.500000   321.500000       96.000000      71.000000   \n",
       "max    3123.000000  3002.000000  2442.000000      986.000000     825.000000   \n",
       "\n",
       "       ...       # Male      # Asian      # Black   # Hispanic  \\\n",
       "count  ...   410.000000   410.000000   410.000000   410.000000   \n",
       "mean   ...   355.360976   125.875610   177.643902   275.914634   \n",
       "std    ...   417.913090   339.852782   178.264522   257.617379   \n",
       "min    ...     0.000000     0.000000     0.000000    11.000000   \n",
       "25%    ...   164.000000     7.000000    75.000000   109.250000   \n",
       "50%    ...   226.500000    18.500000   125.000000   212.000000   \n",
       "75%    ...   338.500000    80.750000   214.500000   331.750000   \n",
       "max    ...  3531.000000  3545.000000  1107.000000  1602.000000   \n",
       "\n",
       "       # Multi-Racial  # Native American      # White  \\\n",
       "count      410.000000         410.000000   410.000000   \n",
       "mean         4.063415           6.802439   102.631707   \n",
       "std         12.390385          13.142160   273.181864   \n",
       "min          0.000000           0.000000     0.000000   \n",
       "25%          0.000000           2.000000     7.000000   \n",
       "50%          1.000000           3.000000    13.500000   \n",
       "75%          3.000000           7.000000    61.750000   \n",
       "max        151.000000         130.000000  3020.000000   \n",
       "\n",
       "       # English Language Learners    # Poverty  Economic Need Index  \n",
       "count                   410.000000   410.000000           410.000000  \n",
       "mean                     83.951220   523.686707            77.078537  \n",
       "std                     128.573583   540.472580            15.901799  \n",
       "min                       0.000000    53.000000            23.200000  \n",
       "25%                      15.000000   268.750000            70.800000  \n",
       "50%                      34.500000   365.500000            80.850000  \n",
       "75%                      84.750000   487.837500            88.975000  \n",
       "max                    1021.000000  3527.000000            95.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistical Details of the dataset\n",
    "merge_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174fa35",
   "metadata": {},
   "source": [
    "# PreProcessing the Data\n",
    "## Define X and Y\n",
    "This is like extracting dependent and independent variables.\n",
    "\n",
    "We have to define x and y for the model. x and y are input and output features of the dataset. So taking x features as input values that are independent, our model will predict the outcome which is y that are dependent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358dd71",
   "metadata": {},
   "source": [
    "## 1.First, we define the features set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efee25d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ell_num</th>\n",
       "      <th>sped_num</th>\n",
       "      <th>male_num</th>\n",
       "      <th>female_num</th>\n",
       "      <th>Total Cohort #</th>\n",
       "      <th>Total Grads #</th>\n",
       "      <th>Total Regents #</th>\n",
       "      <th>Advanced Regents #</th>\n",
       "      <th>Regents w/o Advanced #</th>\n",
       "      <th>Local #</th>\n",
       "      <th>...</th>\n",
       "      <th># Male</th>\n",
       "      <th># Asian</th>\n",
       "      <th># Black</th>\n",
       "      <th># Hispanic</th>\n",
       "      <th># Multi-Racial</th>\n",
       "      <th># Native American</th>\n",
       "      <th># White</th>\n",
       "      <th># English Language Learners</th>\n",
       "      <th># Poverty</th>\n",
       "      <th>Economic Need Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>59</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>267</td>\n",
       "      <td>141</td>\n",
       "      <td>100</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>415.0</td>\n",
       "      <td>82.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>76</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>81</td>\n",
       "      <td>113</td>\n",
       "      <td>367</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>447.0</td>\n",
       "      <td>62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>70</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>176.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>234</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>318</td>\n",
       "      <td>58</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>392</td>\n",
       "      <td>431.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ell_num  sped_num  male_num  female_num  Total Cohort #  Total Grads #  \\\n",
       "0     52.0     124.0     281.0       234.0               5            4.0   \n",
       "1     54.0     111.0     275.0       213.0              59           31.0   \n",
       "2     27.0     146.0     285.0       261.0              76           65.0   \n",
       "3      4.0      19.0      96.0       117.0              70           12.0   \n",
       "4    462.0       4.0     314.0       237.0             234           59.0   \n",
       "\n",
       "   Total Regents #  Advanced Regents #  Regents w/o Advanced #  Local #  ...  \\\n",
       "0              0.0                 0.0                     0.0      4.0  ...   \n",
       "1             19.0                 3.0                    16.0     12.0  ...   \n",
       "2             64.0                 0.0                    64.0      1.0  ...   \n",
       "3              9.0                 0.0                     9.0      3.0  ...   \n",
       "4             59.0                37.0                    22.0      0.0  ...   \n",
       "\n",
       "   # Male  # Asian  # Black  # Hispanic  # Multi-Racial  # Native American  \\\n",
       "0     125       27       58         127               0                  4   \n",
       "1     267      141      100         206               1                  2   \n",
       "2     366       81      113         367               6                  6   \n",
       "3      86        1       70         121               1                  1   \n",
       "4     320      318       58         165               0                  6   \n",
       "\n",
       "   # White  # English Language Learners  # Poverty  Economic Need Index  \n",
       "0        6                           21      191.0                 87.8  \n",
       "1       15                           49      415.0                 82.9  \n",
       "2      100                            6      447.0                 62.9  \n",
       "3        9                           16      176.0                 85.0  \n",
       "4       10                          392      431.0                 95.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features set.\n",
    "X = merge_df.copy()\n",
    "X = X.drop(columns=[\"DBN\",\"asian_num\",\"black_num\",\"hispanic_num\",\"white_num\",\"School Name\",\"Year\",\"Dropped Out #\"])\n",
    "            \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74979e",
   "metadata": {},
   "source": [
    "## 2.Next, we define the target set. Here, we're using the ravel() method, which performs the same procedure on our target set data as the values attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8b2fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   6.,   2.,  40., 104.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set.\n",
    "y = merge_df[\"Dropped Out #\"].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eef90",
   "metadata": {},
   "source": [
    "## 3. Now, we split into the training and testing sets.\n",
    "##   Now, split our dataset into two parts in which 80% of the dataset will go to the training set, and 20% of the dataset will go to the testing set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256d8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting into Train and Test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2,random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bee765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (328, 23)\n",
      "X_test :  (82, 23)\n",
      "y_train :  (328,)\n",
      "y_test :  (82,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train, X_test, y_train, and y_test. Add the following code to do this:\n",
    "\n",
    "print(\"X_train : \",X_train.shape)\n",
    "\n",
    "print(\"X_test : \",X_test.shape)\n",
    "\n",
    "print(\"y_train : \",y_train.shape)\n",
    "\n",
    "print(\"y_test : \",y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02036509",
   "metadata": {},
   "source": [
    "#   feature engineering and the feature selection\n",
    "## Fit the Model, Make Predictions, and Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1841b4",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ea9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a random forest regressor.\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=78) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c91938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=78)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44968128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9316cc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6075674602498352"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance.\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9c5c4",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81ec68d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Decision Tree Regression model on the Training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rf_model = DecisionTreeRegressor(random_state = 0)\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "122b95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a65426b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for a worse model is -0.27157994218157877\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance.\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,predictions)\n",
    "print('r2 score for a worse model is', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a187c4c",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c83dc882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Support Vector Regression model on the Training set\n",
    "from sklearn.svm import SVR\n",
    "rf_model = SVR(kernel = 'rbf')\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "rf_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b7e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40dd0029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08506255826618381"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance.\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f7cc2",
   "metadata": {},
   "source": [
    "##  multiple linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20890a95",
   "metadata": {},
   "source": [
    "## To train the model, we have to import the Linear Regression model. Use the fit method, and pass the training sets into it to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7781c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the multiple regression model on the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "rf_model = LinearRegression()\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265bb57",
   "metadata": {},
   "source": [
    "## Predict the Test Results\n",
    "Use the predict method to predict the results, then pass the independent variables into it and view the results. It will give the array with all the values in it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a9bff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.83926200e-01,  7.68135315e+00,  5.10463361e+00,  3.62234243e+00,\n",
       "        7.82483547e+00, -1.07073893e+00,  5.88761834e+01,  1.80159395e+00,\n",
       "        7.11757617e+00,  1.30949030e+01,  1.68783663e+01,  1.02681466e+01,\n",
       "        1.84978724e+01, -2.49966989e+00, -9.34626768e-01, -7.16495156e-01,\n",
       "        1.26926186e+01,  1.36255058e+01, -7.26905614e-01, -3.16627671e+00,\n",
       "        3.04866594e+00, -2.38970814e-01, -1.67403871e+00,  1.96318410e+00,\n",
       "        6.99897397e+00,  2.29542186e+02,  2.64206889e+00,  3.47485458e+00,\n",
       "        2.44046153e+00,  1.50470489e+00,  5.01250711e-01,  4.67952502e+00,\n",
       "        1.03498038e+01, -4.38444255e-01,  3.28798918e+00,  1.58361895e+00,\n",
       "        3.31900412e-01,  8.71141827e+00,  2.50956767e+00,  2.31223634e+00,\n",
       "       -1.63971337e-01,  9.45616352e+00,  8.60084550e+00,  2.71063706e+01,\n",
       "        3.40480874e+00,  7.85567075e+00,  2.02951185e-01,  1.34505004e+01,\n",
       "        2.10715976e+00,  4.66238056e+00,  8.91758072e+00, -1.44652249e+00,\n",
       "        8.32088035e+00,  1.03623517e+01,  4.11750660e+00,  2.17172479e+01,\n",
       "        4.98932340e+00,  1.90726637e+00,  1.44256645e+01,  1.81747809e+01,\n",
       "        4.18840561e+00,  5.95829550e+00,  1.23166178e+00,  1.98815563e+00,\n",
       "        2.01564085e+01,  3.36137377e+00,  2.03211990e+00,  1.68306978e+01,\n",
       "       -2.42547971e+00,  5.00538048e+01,  3.40073747e+01,  1.17832524e+01,\n",
       "        2.53460900e+01,  2.64722810e+00,  6.94796762e+00,  7.37758461e-01,\n",
       "        2.49981053e+01,  1.21049709e+00,  4.19730731e+00,  8.90205745e+00,\n",
       "        8.54469333e-01,  2.40609376e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "predictions = rf_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f128ac8",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "We have different metrics to find the accuracy score of the model, and here we use r2_score to evaluate our model and find its accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b427cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844782486300152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance.\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c2a06",
   "metadata": {},
   "source": [
    "## Predicted Values\n",
    "Let us create a new data frame that contains actual values, predicted values, and differences between them so that we will understand how near the model predicts its actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80746efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'Actual Value':y_test,'Predicted Value':predictions,'Difference':y_test-predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a051eb30",
   "metadata": {},
   "source": [
    "## View the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14e73f4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183926</td>\n",
       "      <td>-0.183926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.681353</td>\n",
       "      <td>1.318647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.104634</td>\n",
       "      <td>-1.104634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.622342</td>\n",
       "      <td>0.377658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.824835</td>\n",
       "      <td>-1.824835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.210497</td>\n",
       "      <td>0.789503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.197307</td>\n",
       "      <td>-0.197307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.902057</td>\n",
       "      <td>1.097943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854469</td>\n",
       "      <td>0.145531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.406094</td>\n",
       "      <td>-0.406094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Value  Predicted Value  Difference\n",
       "0            0.0         0.183926   -0.183926\n",
       "1            9.0         7.681353    1.318647\n",
       "2            4.0         5.104634   -1.104634\n",
       "3            4.0         3.622342    0.377658\n",
       "4            6.0         7.824835   -1.824835\n",
       "..           ...              ...         ...\n",
       "77           2.0         1.210497    0.789503\n",
       "78           4.0         4.197307   -0.197307\n",
       "79          10.0         8.902057    1.097943\n",
       "80           1.0         0.854469    0.145531\n",
       "81           2.0         2.406094   -0.406094\n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945cbe5d",
   "metadata": {},
   "source": [
    "## Here we can see the difference between Actual values and predicted values which are not very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d9cb0",
   "metadata": {},
   "source": [
    "## Plot the Results\n",
    "We will plot the scatter plot between actual values and predicted values. Use xlabel to label the x-axis and use ylabel to label the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a31a2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,predictions);\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525bcb2b",
   "metadata": {},
   "source": [
    "## Regression plot of our model.\n",
    "\n",
    "A regression plot is useful to understand the linear relationship between two parameters. It creates a regression line in-between those parameters and then plots a scatter plot of those data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea5770a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=predictions,ci=None,color ='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fb45813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression: 98%\n",
      "Support Vector Regression: 5%\n",
      "Decision Tree Regression: 35%\n",
      "Random Forest Regression: 61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Multiple linear regression: 98%\")\n",
    "print(\"Support Vector Regression: 5%\")\n",
    "print(\"Decision Tree Regression: 35%\")\n",
    "print(\"Random Forest Regression: 61%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e9dd7",
   "metadata": {},
   "source": [
    "## Multiple linear regression performed the best out of all the four regression models. So we decided to go with this model to predict output values. We didn't see any limitations as the accuracy score is near 100%.\n",
    "## Benefit: This approach has led to a more accurate and precise understanding of the association of each factor with the outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec3967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
